<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.23.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.json","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="使用NumPy实现高斯朴素贝叶斯分类器：鸢尾花数据集全流程教程 1. 高斯朴素贝叶斯算法原理 高斯朴素贝叶斯是基于贝叶斯定理和特征条件独立假设的分类算法。它假设每个特征在给定类别下服从高斯分布（正态分布），适用于连续型特征数据。 1.1 贝叶斯定理公式 朴素贝叶斯分类器的核心是贝叶斯定理： $$P(y|x_1,x_2,...,x_n) &#x3D; \frac{P(y)\prod_{i&#x3D;1}^n">
<meta property="og:type" content="article">
<meta property="og:title" content="使用NumPy实现高斯朴素贝叶斯分类器：鸢尾花数据集全流程教程">
<meta property="og:url" content="http://example.com/posts/2510.003v1/index.html">
<meta property="og:site_name" content="Feixiang Shu&#39;s Blog">
<meta property="og:description" content="使用NumPy实现高斯朴素贝叶斯分类器：鸢尾花数据集全流程教程 1. 高斯朴素贝叶斯算法原理 高斯朴素贝叶斯是基于贝叶斯定理和特征条件独立假设的分类算法。它假设每个特征在给定类别下服从高斯分布（正态分布），适用于连续型特征数据。 1.1 贝叶斯定理公式 朴素贝叶斯分类器的核心是贝叶斯定理： $$P(y|x_1,x_2,...,x_n) &#x3D; \frac{P(y)\prod_{i&#x3D;1}^n">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-04T16:00:00.000Z">
<meta property="article:modified_time" content="2025-10-05T14:44:18.673Z">
<meta property="article:author" content="Feixiang Shu">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/posts/2510.003v1/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/posts/2510.003v1/","path":"/posts/2510.003v1/","title":"使用NumPy实现高斯朴素贝叶斯分类器：鸢尾花数据集全流程教程"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>使用NumPy实现高斯朴素贝叶斯分类器：鸢尾花数据集全流程教程 | Feixiang Shu's Blog</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Feixiang Shu's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8numpy%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%96%AF%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E9%B8%A2%E5%B0%BE%E8%8A%B1%E6%95%B0%E6%8D%AE%E9%9B%86%E5%85%A8%E6%B5%81%E7%A8%8B%E6%95%99%E7%A8%8B"><span class="nav-number">1.</span> <span class="nav-text">使用NumPy实现高斯朴素贝叶斯分类器：鸢尾花数据集全流程教程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AB%98%E6%96%AF%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="nav-number">1.1.</span> <span class="nav-text">1. 高斯朴素贝叶斯算法原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86%E5%85%AC%E5%BC%8F"><span class="nav-number">1.1.1.</span> <span class="nav-text">1.1 贝叶斯定理公式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%AB%98%E6%96%AF%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0"><span class="nav-number">1.1.2.</span> <span class="nav-text">1.2 高斯概率密度函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%B8%A2%E5%B0%BE%E8%8A%B1%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.2.</span> <span class="nav-text">2. 鸢尾花数据集介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD"><span class="nav-number">1.3.</span> <span class="nav-text">3. 环境准备与数据加载</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E4%B8%8E%E6%A0%87%E5%87%86%E5%8C%96"><span class="nav-number">1.4.</span> <span class="nav-text">4. 数据预处理与标准化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AB%98%E6%96%AF%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E5%AE%9E%E7%8E%B0"><span class="nav-number">1.5.</span> <span class="nav-text">5. 高斯朴素贝叶斯分类器实现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E8%AF%84%E4%BC%B0"><span class="nav-number">1.6.</span> <span class="nav-text">6. 模型训练与评估</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-number">1.7.</span> <span class="nav-text">7. 特征条件概率矩阵可视化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B3%E9%94%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93"><span class="nav-number">1.8.</span> <span class="nav-text">8. 关键知识点总结</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E5%80%BC%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%A4%84%E7%90%86"><span class="nav-number">1.8.1.</span> <span class="nav-text">8.1 数值稳定性处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-number">1.8.2.</span> <span class="nav-text">8.2 算法优缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">1.8.3.</span> <span class="nav-text">8.3 应用场景</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%AD%A6%E4%B9%A0%E5%BB%BA%E8%AE%AE"><span class="nav-number">1.9.</span> <span class="nav-text">9. 进一步学习建议</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Feixiang Shu"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Feixiang Shu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">20</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/sfmoraa" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;sfmoraa" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:sfx-sjtu@sjtu.edu.cn" title="E-Mail → mailto:sfx-sjtu@sjtu.edu.cn" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/posts/2510.003v1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Feixiang Shu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Feixiang Shu's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="使用NumPy实现高斯朴素贝叶斯分类器：鸢尾花数据集全流程教程 | Feixiang Shu's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          使用NumPy实现高斯朴素贝叶斯分类器：鸢尾花数据集全流程教程
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-10-05 00:00:00 / 修改时间：22:44:18" itemprop="dateCreated datePublished" datetime="2025-10-05T00:00:00+08:00">2025-10-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E4%B9%A0%E6%8F%90%E5%8D%87/" itemprop="url" rel="index"><span itemprop="name">学习提升</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E4%B9%A0%E6%8F%90%E5%8D%87/%E5%8A%A8%E6%80%81%E5%9B%BE%E4%B8%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">动态图与大模型学习</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>13 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1
id="使用numpy实现高斯朴素贝叶斯分类器鸢尾花数据集全流程教程">使用NumPy实现高斯朴素贝叶斯分类器：鸢尾花数据集全流程教程</h1>
<h2 id="高斯朴素贝叶斯算法原理">1. 高斯朴素贝叶斯算法原理</h2>
<p>高斯朴素贝叶斯是基于贝叶斯定理和特征条件独立假设的分类算法。它假设每个特征在给定类别下服从高斯分布（正态分布），适用于连续型特征数据。</p>
<h3 id="贝叶斯定理公式">1.1 贝叶斯定理公式</h3>
<p>朴素贝叶斯分类器的核心是贝叶斯定理： <span
class="math display">$$P(y|x_1,x_2,...,x_n) = \frac{P(y)\prod_{i=1}^n
P(x_i|y)}{P(x_1,x_2,...,x_n)}$$</span></p>
<p>其中： - <span
class="math inline"><em>P</em>(<em>y</em>|<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, ..., <em>x</em><sub><em>n</em></sub>)</span>
是后验概率（给定特征下属于某类的概率） - <span
class="math inline"><em>P</em>(<em>y</em>)</span>
是先验概率（各类别的初始概率） - <span
class="math inline"><em>P</em>(<em>x</em><sub><em>i</em></sub>|<em>y</em>)</span>
是似然概率（某类别下特征出现的概率） -
分母是证据因子，在实际比较中可以忽略</p>
<h3 id="高斯概率密度函数">1.2 高斯概率密度函数</h3>
<p>对于连续特征，使用高斯概率密度函数： <span
class="math display">$$P(x_i|y) = \frac{1}{\sqrt{2\pi\sigma_y^2}}
\exp\left(-\frac{(x_i - \mu_y)^2}{2\sigma_y^2}\right)$$</span> 其中
<span class="math inline"><em>μ</em><sub><em>y</em></sub></span>
是特征在类别 y 下的均值，<span
class="math inline"><em>σ</em><sub><em>y</em></sub></span>
是标准差。</p>
<h2 id="鸢尾花数据集介绍">2. 鸢尾花数据集介绍</h2>
<p>鸢尾花数据集包含3类鸢尾花（山鸢尾、变色鸢尾、维吉尼亚鸢尾），每类50个样本，每个样本有4个特征：
- 花萼长度（sepal length） - 花萼宽度（sepal width） - 花瓣长度（petal
length） - 花瓣宽度（petal width）</p>
<h2 id="环境准备与数据加载">3. 环境准备与数据加载</h2>
<p>首先导入必要的库并加载数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载鸢尾花数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data  <span class="comment"># 特征数据</span></span><br><span class="line">y = iris.target  <span class="comment"># 标签数据</span></span><br><span class="line">feature_names = iris.feature_names  <span class="comment"># 特征名称</span></span><br><span class="line">target_names = iris.target_names  <span class="comment"># 类别名称</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;数据集形状:&quot;</span>, X.shape,y.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征名称:&quot;</span>, feature_names)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;类别名称:&quot;</span>, target_names)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;各类别样本数:&quot;</span>, np.bincount(y))</span><br></pre></td></tr></table></figure>
<h2 id="数据预处理与标准化">4. 数据预处理与标准化</h2>
<p>数据标准化是将特征数据缩放到均值为0，标准差为1的分布，这有助于提高高斯朴素贝叶斯的性能。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 划分训练集和测试集（70%训练，30%测试）</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class="line">    X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>, stratify=y</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_mean = np.mean(X_train, axis=<span class="number">0</span>)</span><br><span class="line">train_std = np.std(X_train, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">standardize_data</span>(<span class="params">X,mean,std</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    对数据进行标准化处理</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    X_standardized = (X - mean) / std  <span class="comment"># 标准化公式</span></span><br><span class="line">    <span class="keyword">return</span> X_standardized</span><br><span class="line"></span><br><span class="line">X_train_standardized = standardize_data(X_train, train_mean, train_std)</span><br><span class="line">X_test_standardized = standardize_data(X_test, train_mean, train_std)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练集形状:&quot;</span>, X_train_standardized.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试集形状:&quot;</span>, X_test_standardized.shape)</span><br></pre></td></tr></table></figure>
<h2 id="高斯朴素贝叶斯分类器实现">5. 高斯朴素贝叶斯分类器实现</h2>
<p>下面是用NumPy从头实现高斯朴素贝叶斯分类器的完整代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GaussianNaiveBayes</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    高斯朴素贝叶斯分类器实现</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.classes = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.priors = &#123;&#125;  <span class="comment"># 先验概率</span></span><br><span class="line">        <span class="variable language_">self</span>.means = &#123;&#125;   <span class="comment"># 每个类别下特征的均值</span></span><br><span class="line">        <span class="variable language_">self</span>.stds = &#123;&#125;    <span class="comment"># 每个类别下特征的标准差</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        训练模型：计算先验概率、均值和标准差</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.classes = np.unique(y)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> <span class="variable language_">self</span>.classes:</span><br><span class="line">            <span class="comment"># 获取当前类别的所有样本</span></span><br><span class="line">            X_c = X[y == c]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算先验概率（该类样本数占总样本数的比例）</span></span><br><span class="line">            <span class="variable language_">self</span>.priors[c] = X_c.shape[<span class="number">0</span>] / X.shape[<span class="number">0</span>]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算每个特征的均值和标准差</span></span><br><span class="line">            <span class="variable language_">self</span>.means[c] = np.mean(X_c, axis=<span class="number">0</span>)</span><br><span class="line">            <span class="variable language_">self</span>.stds[c] = np.std(X_c, axis=<span class="number">0</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 避免标准差为0导致除零错误（添加一个很小的值）</span></span><br><span class="line">            <span class="variable language_">self</span>.stds[c] = np.where(<span class="variable language_">self</span>.stds[c] == <span class="number">0</span>, <span class="number">1e-9</span>, <span class="variable language_">self</span>.stds[c])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_gaussian_pdf</span>(<span class="params">self, x, mean, std</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        计算高斯概率密度函数</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        exponent = np.exp(-<span class="number">0.5</span> * ((x - mean) ** <span class="number">2</span>) / (std ** <span class="number">2</span>))</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">1</span> / (np.sqrt(<span class="number">2</span> * np.pi) * std)) * exponent</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_calculate_log_likelihood</span>(<span class="params">self, x, c</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        计算对数似然概率（使用对数防止数值下溢）</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        likelihood = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x)):</span><br><span class="line">            <span class="comment"># 使用高斯PDF计算每个特征的条件概率</span></span><br><span class="line">            prob = <span class="variable language_">self</span>._gaussian_pdf(x[i], <span class="variable language_">self</span>.means[c][i], <span class="variable language_">self</span>.stds[c][i])</span><br><span class="line">            <span class="comment"># 使用对数相加代替概率相乘，避免数值下溢</span></span><br><span class="line">            likelihood += np.log(prob + <span class="number">1e-9</span>)  <span class="comment"># 添加小值避免log(0)</span></span><br><span class="line">        <span class="keyword">return</span> likelihood</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict_single</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        预测单个样本的类别</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        best_class = <span class="literal">None</span></span><br><span class="line">        max_log_posterior = -np.inf</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> <span class="variable language_">self</span>.classes:</span><br><span class="line">            <span class="comment"># 计算对数先验概率</span></span><br><span class="line">            log_prior = np.log(<span class="variable language_">self</span>.priors[c])</span><br><span class="line">            <span class="comment"># 计算对数似然概率</span></span><br><span class="line">            log_likelihood = <span class="variable language_">self</span>._calculate_log_likelihood(x, c)</span><br><span class="line">            <span class="comment"># 对数后验概率 = 对数先验 + 对数似然</span></span><br><span class="line">            log_posterior = log_prior + log_likelihood</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> log_posterior &gt; max_log_posterior:</span><br><span class="line">                max_log_posterior = log_posterior</span><br><span class="line">                best_class = c</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> best_class</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        预测多个样本的类别</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        predictions = []</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> X:</span><br><span class="line">            predictions.append(<span class="variable language_">self</span>.predict_single(x))</span><br><span class="line">        <span class="keyword">return</span> np.array(predictions)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self, X, y</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        计算模型准确率</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        y_pred = <span class="variable language_">self</span>.predict(X)</span><br><span class="line">        accuracy = np.<span class="built_in">sum</span>(y_pred == y) / <span class="built_in">len</span>(y)</span><br><span class="line">        <span class="keyword">return</span> accuracy</span><br></pre></td></tr></table></figure>
<h2 id="模型训练与评估">6. 模型训练与评估</h2>
<p>现在使用我们实现的分类器进行训练和预测：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建模型实例</span></span><br><span class="line">gnb = GaussianNaiveBayes()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">gnb.fit(X_train_standardized, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在测试集上进行预测</span></span><br><span class="line">y_pred = gnb.predict(X_test_standardized)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line">accuracy = gnb.score(X_test_standardized, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型准确率: <span class="subst">&#123;accuracy:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 详细评估结果</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report, confusion_matrix</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n分类报告:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred, target_names=target_names))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;混淆矩阵:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br></pre></td></tr></table></figure>
<h2 id="特征条件概率矩阵可视化">7. 特征条件概率矩阵可视化</h2>
<p>为了更好地理解模型，我们可以可视化每个类别下特征的高斯分布：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">visualize_feature_distributions</span>(<span class="params">model, feature_names, target_names</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    可视化每个特征在不同类别下的高斯分布</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">2</span>, figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">    axes = axes.ravel()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 生成测试数据点（标准化后的范围）</span></span><br><span class="line">    x_range = np.linspace(-<span class="number">3</span>, <span class="number">3</span>, <span class="number">100</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> feature_idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> model.classes:</span><br><span class="line">            mean = model.means[c][feature_idx]</span><br><span class="line">            std = model.stds[c][feature_idx]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算高斯分布</span></span><br><span class="line">            y_dist = (<span class="number">1</span> / (np.sqrt(<span class="number">2</span> * np.pi) * std)) * \</span><br><span class="line">                    np.exp(-<span class="number">0.5</span> * ((x_range - mean) ** <span class="number">2</span>) / (std ** <span class="number">2</span>))</span><br><span class="line">            </span><br><span class="line">            axes[feature_idx].plot(x_range, y_dist, </span><br><span class="line">                                  label=<span class="string">f&#x27;<span class="subst">&#123;target_names[c]&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        axes[feature_idx].set_title(<span class="string">f&#x27;<span class="subst">&#123;feature_names[feature_idx]&#125;</span>分布&#x27;</span>)</span><br><span class="line">        axes[feature_idx].set_xlabel(<span class="string">&#x27;标准化值&#x27;</span>)</span><br><span class="line">        axes[feature_idx].set_ylabel(<span class="string">&#x27;概率密度&#x27;</span>)</span><br><span class="line">        axes[feature_idx].legend()</span><br><span class="line">    </span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用可视化函数</span></span><br><span class="line">visualize_feature_distributions(gnb, feature_names, target_names)</span><br></pre></td></tr></table></figure>
<h2 id="关键知识点总结">8. 关键知识点总结</h2>
<h3 id="数值稳定性处理">8.1 数值稳定性处理</h3>
<p>在实际实现中，我们需要注意数值稳定性： -
<strong>避免除零错误</strong>：为标准差添加一个小值（如1e-9） -
<strong>防止数值下溢</strong>：使用对数概率代替原始概率相乘 -
<strong>拉普拉斯平滑</strong>：对于概率计算添加平滑项</p>
<h3 id="算法优缺点">8.2 算法优缺点</h3>
<p><strong>优点</strong>： - 简单易懂，实现容易 - 训练和预测速度快 -
对小规模数据表现良好 - 对缺失数据不敏感</p>
<p><strong>缺点</strong>： - 特征独立性假设在现实中往往不成立 -
对输入数据的分布假设比较严格 - 当特征相关性较强时性能可能下降</p>
<h3 id="应用场景">8.3 应用场景</h3>
<p>高斯朴素贝叶斯特别适用于： - 特征为连续值的分类问题 -
需要快速原型验证的场景 - 数据维度较高的文本分类（配合TF-IDF等特征提取）
- 实时预测系统</p>
<h2 id="进一步学习建议">9. 进一步学习建议</h2>
<ol type="1">
<li><strong>尝试不同的数据集</strong>：如帕金森数据集，比较不同数据集上的表现</li>
<li><strong>实现其他变种</strong>：如多项式朴素贝叶斯（用于离散特征）和伯努利朴素贝叶斯</li>
<li><strong>参数调优</strong>：研究平滑参数对模型性能的影响</li>
<li><strong>与其他算法对比</strong>：比较与逻辑回归、SVM等算法的性能差异</li>
</ol>
<p>通过本教程，您应该已经掌握了使用NumPy实现高斯朴素贝叶斯分类器的完整流程，包括数据预处理、模型实现、训练预测和结果评估。这种从零开始的实现方式有助于深入理解算法原理和实际应用中的各种细节考虑。</p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/2510.002v1/" rel="prev" title="朴素贝叶斯分类器公式推导与实现教程">
                  <i class="fa fa-angle-left"></i> 朴素贝叶斯分类器公式推导与实现教程
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/posts/2510.004v1/" rel="next" title="机器学习模型评估体系完整教程：从交叉验证到超参数调优">
                  机器学习模型评估体系完整教程：从交叉验证到超参数调优 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Feixiang Shu</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">81k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">2:26</span>
  </span>
</div>

<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("05/21/2025 10:00:00"); 
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒.";
    }
setInterval("createtime()",250);
</script>
    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
