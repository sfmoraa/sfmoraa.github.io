<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.23.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.json","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Feixiang Shu&#39;s Blog">
<meta property="og:url" content="http://example.com/null-index/page/17/index.html">
<meta property="og:site_name" content="Feixiang Shu&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Feixiang Shu">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/null-index/page/17/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"null-index/page/17/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Feixiang Shu's Blog</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Feixiang Shu's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Feixiang Shu"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Feixiang Shu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">18</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/sfmoraa" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;sfmoraa" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:sfx-sjtu@sjtu.edu.cn" title="E-Mail → mailto:sfx-sjtu@sjtu.edu.cn" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/posts/2505.001v1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Feixiang Shu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Feixiang Shu's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Feixiang Shu's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/2505.001v1/" class="post-title-link" itemprop="url">使用LoRA微调Llama-2-7b-hf实现涉诈短信识别</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-05-19 00:00:00" itemprop="dateCreated datePublished" datetime="2025-05-19T00:00:00+08:00">2025-05-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-24 13:00:06" itemprop="dateModified" datetime="2025-05-24T13:00:06+08:00">2025-05-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/LLM%E5%AE%9E%E8%B7%B5/" itemprop="url" rel="index"><span itemprop="name">LLM实践</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/LLM%E5%AE%9E%E8%B7%B5/LoRA/" itemprop="url" rel="index"><span itemprop="name">LoRA</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>10 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本博客为2024挑战杯项目<strong>基于大模型的多模态风险内容识别系统</strong>的涉诈短信识别功能的实现。</p>
<h2 id="方案选择"><a href="#方案选择" class="headerlink" title="方案选择"></a>方案选择</h2><p>Huggingface格式LLama模型+Lora代码微调</p>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>GPU服务器：RTX 4090，24G双GPU，cuda12</p>
<p>Python: 3.11</p>
<p>由于40系GPU不支持某些高效的通信模式，需要设置环境变量：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export NCCL_P2P_DISABLE=1</span><br><span class="line">export NCCL_IB_DISABLE=1</span><br></pre></td></tr></table></figure>



<h2 id="模型准备"><a href="#模型准备" class="headerlink" title="模型准备"></a>模型准备</h2><h4 id="模型下载"><a href="#模型下载" class="headerlink" title="模型下载"></a>模型下载</h4><p>下载Llama-2-7b-hf模型，使用的是Llama中文社区整理的模型资源。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/LlamaFamily/Llama-Chinese">LlamaFamily&#x2F;Llama-Chinese: Llama中文社区，实时汇总最新Llama学习资料，构建最好的中文Llama大模型开源生态，完全开源可商用</a></p>
<h4 id="模型验证"><a href="#模型验证" class="headerlink" title="模型验证"></a>模型验证</h4><p>可以用以下代码测试下载的模型的效果，注意修改模型保存的路径，此处为&#x2F;home&#x2F;data&#x2F;pre_model&#x2F;Llama-2-7b-hf。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">from transformers import AutoTokenizer, AutoModelForCausalLM</span><br><span class="line">import torch</span><br><span class="line"></span><br><span class="line">model_path = &quot;/home/data/pre_model/Llama-2-7b-hf&quot;</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_path)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    model_path,</span><br><span class="line">    device_map=&quot;auto&quot;,        # 自动分配GPU资源</span><br><span class="line">).eval()                      # 启用评估模式提升推理速度</span><br><span class="line"></span><br><span class="line">input_text = &quot;How to learn skiing?&quot; </span><br><span class="line">inputs = tokenizer(input_text, return_tensors=&quot;pt&quot;).to(model.device)</span><br><span class="line"></span><br><span class="line">with torch.inference_mode():  </span><br><span class="line">    outputs = model.generate(</span><br><span class="line">        **inputs,</span><br><span class="line">        max_length=256,</span><br><span class="line">        do_sample=True,       # 启用采样生成更自然文本</span><br><span class="line">        temperature=0.7,      </span><br><span class="line">        top_p=0.9             </span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">print(tokenizer.decode(outputs[0], skip_special_tokens=True))</span><br></pre></td></tr></table></figure>

<p>输出如下，可以看出生成的文本比较流畅。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">How to learn skiing?</span><br><span class="line">Skiing is an exciting and fun winter activity that many people love. While skiing can be challenging at first, with the right instruction and practice, anyone can learn how to ski.</span><br><span class="line">Learning to ski is a process that requires patience and practice. It is important to start with the basics, such as learning how to balance on skis, and progress gradually to more advanced techniques.</span><br><span class="line">The best way to learn how to ski is to take lessons from a qualified instructor. A qualified instructor will be able to teach you the basics of skiing, such as balance, turning, and stopping. They will also be able to teach you more advanced techniques, such as carving and jumping.</span><br><span class="line">Another way to learn how to ski is to practice on a ski slope. Ski slopes are designed to help you learn how to ski safely and effectively. They are usually divided into different levels, so you can start on a beginner slope and gradually progress to more challenging slopes.</span><br><span class="line">It is also important to wear the right equipment when learning how to ski. This includes a helmet, goggles, and warm clothing. Wearing the right</span><br></pre></td></tr></table></figure>



<h2 id="LoRA微调数据集准备"><a href="#LoRA微调数据集准备" class="headerlink" title="LoRA微调数据集准备"></a>LoRA微调数据集准备</h2><p>使用<a target="_blank" rel="noopener" href="https://github.com/ChangMianRen/Telecom_Fraud_Texts_5/tree/main">ChangMianRen&#x2F;Telecom_Fraud_Texts_5</a>，其中包含了大量经过标记的诈骗短信和正常短信样本。</p>
<p>将数据进行预处理，得到符合LoRA微调格式的数据集。</p>
<p>原始数据整理为形如：</p>
<table>
<thead>
<tr>
<th>content</th>
<th>label</th>
</tr>
</thead>
<tbody><tr>
<td>最后小时，在微信添加朋友中输入良品铺子美食旅行关注参与活动并抢最高DIGIT元红包。如需退订请回复TD或直接退出良品铺子的公众号即可！</td>
<td>0</td>
</tr>
<tr>
<td>你好，我是贷款公司的代表。你是否有资金需求？我们提供低利率、快速审批的贷款服务。如果你感兴趣的话请添加我的微信号：xxxxxxxxx。</td>
<td>1</td>
</tr>
<tr>
<td>你好，是满梦园吗？我这里是公安机关的民警。我们发现您的身份信息可能被泄露了，涉嫌诈骗活动。我们需要您协助调查此事。请下载我们的”teams”app并与我们在上面进行交流。谢谢配合！</td>
<td>1</td>
</tr>
</tbody></table>
<p>应用的模版为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;&quot;</span><br><span class="line">            ### Instruction:</span><br><span class="line">            你是一个专门识别诈骗短信的专家，请判断输入的短信是否是诈骗短信，如果是，请回答True，否则回答False。</span><br><span class="line">            诈骗短信一般具有以下特征：</span><br><span class="line">            1. 诱导点击链接或拨打电话或添加微信</span><br><span class="line">            2. 内容涉及赌博、中奖、钱财等</span><br><span class="line">            3. 使用特殊符号或文字，或使用符号隔断文字</span><br><span class="line">            4. 使用黑话/暗语，令人难以理解</span><br><span class="line"></span><br><span class="line">            ### Input:&#123;&#125;</span><br><span class="line"></span><br><span class="line">            ### Response:&#123;&#125;</span><br><span class="line">            &lt;/s&gt;&quot;&quot;&quot;</span><br></pre></td></tr></table></figure>

<p>将数据中的content作为input，label为1时Response为True，为0时Response为False。</p>
<h2 id="微调代码"><a href="#微调代码" class="headerlink" title="微调代码"></a>微调代码</h2><p>训练器的参数意义可以参考<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/363670628">huggingface transformers使用指南之二——方便的trainer - 知乎</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">from peft import get_peft_model, LoraConfig, TaskType</span><br><span class="line">from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments</span><br><span class="line">from trl import SFTTrainer,SFTConfig</span><br><span class="line">from torch.utils.data import Dataset</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">class SMSDataset(Dataset):</span><br><span class="line">    def __init__(self, data_path):</span><br><span class="line">        self.data = pd.read_csv(data_path)</span><br><span class="line">        self.prompt_template = &quot;&quot;&quot;</span><br><span class="line">            ### Instruction:</span><br><span class="line">            你是一个专门识别诈骗短信的专家，请判断输入的短信是否是诈骗短信，如果是，请回答True，否则回答False。</span><br><span class="line">            诈骗短信一般具有以下特征：</span><br><span class="line">            1. 诱导点击链接或拨打电话或添加微信</span><br><span class="line">            2. 内容涉及赌博、中奖、钱财等</span><br><span class="line">            3. 使用特殊符号或文字，或使用符号隔断文字</span><br><span class="line">            4. 使用黑话/暗语，令人难以理解</span><br><span class="line"></span><br><span class="line">            ### Input:&#123;&#125;</span><br><span class="line"></span><br><span class="line">            ### Response:&#123;&#125;</span><br><span class="line">            &lt;/s&gt;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        return len(self.data)</span><br><span class="line">    </span><br><span class="line">    def __getitem__(self, idx):</span><br><span class="line">        raw_data = self.data.iloc[idx]</span><br><span class="line">        prompt_data=self.prompt_template.format(raw_data[&#x27;content&#x27;],&quot;True&quot; if raw_data[&#x27;label&#x27;]==1 else &quot;False&quot;)</span><br><span class="line">        prompt_data=tokenizer(prompt_data)</span><br><span class="line">        return prompt_data</span><br><span class="line"></span><br><span class="line">SMStrainDataset = SMSDataset(&quot;./train.csv&quot;)</span><br><span class="line">SMSvalidDataset = SMSDataset(&quot;./valid.csv&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model_path = &quot;/home/data/pre_model/Llama-2-7b-hf&quot;</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    model_path,</span><br><span class="line">    device_map=&quot;auto&quot;,       </span><br><span class="line">    # load_in_8bit=True</span><br><span class="line">)   </span><br><span class="line">model.enable_input_require_grads()</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_path)</span><br><span class="line">tokenizer.pad_token = tokenizer.eos_token</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lora_config = LoraConfig(</span><br><span class="line">    task_type=TaskType.CAUSAL_LM,  </span><br><span class="line">    inference_mode=False,          </span><br><span class="line">    r=8,                           </span><br><span class="line">    lora_alpha=16,                 </span><br><span class="line">    lora_dropout=0.1,              </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = get_peft_model(model, lora_config)</span><br><span class="line">model.print_trainable_parameters()</span><br><span class="line"></span><br><span class="line">training_args = SFTConfig(</span><br><span class="line">    per_device_train_batch_size=1,</span><br><span class="line">    gradient_accumulation_steps=4,</span><br><span class="line">    warmup_steps = 5,</span><br><span class="line">    num_train_epochs = 1,</span><br><span class="line">    gradient_checkpointing=True,</span><br><span class="line">    #max_steps = 60,</span><br><span class="line">    learning_rate = 2e-4,</span><br><span class="line">    optim = &quot;adamw_torch&quot;,</span><br><span class="line">    weight_decay = 0.01,</span><br><span class="line">    lr_scheduler_type = &quot;cosine&quot;,</span><br><span class="line">    seed = 3407,</span><br><span class="line">    output_dir = &quot;./results&quot;,</span><br><span class="line">    report_to = &quot;none&quot;,</span><br><span class="line">    max_seq_length = 512,</span><br><span class="line">    dataset_num_proc = 4,</span><br><span class="line">    packing = False, </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = SFTTrainer(</span><br><span class="line">    model=model,              </span><br><span class="line">    tokenizer=tokenizer,     </span><br><span class="line">    args=training_args,             </span><br><span class="line">    train_dataset=SMStrainDataset,    </span><br><span class="line">    eval_dataset=SMSvalidDataset,</span><br><span class="line">    peft_config=lora_config,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.train()</span><br><span class="line"></span><br><span class="line">model.save_pretrained(&#x27;./lora_model&#x27;)</span><br></pre></td></tr></table></figure>

<p>值得注意的是，过程中出现了张量不在同一设备的情况，经过检查，在transformers库的loss_utils.py文件内的</p>
<p><strong>ForCausalLMLoss</strong>函数内增加</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_items_in_batch=num_items_in_batch.to(logits.device)</span><br></pre></td></tr></table></figure>

<p>解决了设备不同的问题。</p>
<h2 id="效果验证"><a href="#效果验证" class="headerlink" title="效果验证"></a>效果验证</h2><p>构造测试脚本进行测试，取模型输出的前五个字符作为判断结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rsp=output[len(input_text):].strip()</span><br><span class="line">if &quot;True&quot; in rsp[:5] and label==True:</span><br><span class="line">    current+=1</span><br><span class="line">elif &quot;False&quot; in rsp[:5] and label==False:</span><br><span class="line">    current+=1</span><br></pre></td></tr></table></figure>

<p>对比原始模型和微调后模型结果如下：</p>
<table>
<thead>
<tr>
<th>指标</th>
<th>原始模型</th>
<th>微调后模型</th>
</tr>
</thead>
<tbody><tr>
<td>准确率</td>
<td>0.180</td>
<td>0.977</td>
</tr>
<tr>
<td>F1分数</td>
<td>0.294</td>
<td>0.968</td>
</tr>
</tbody></table>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/null-index/page/16/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/null-index/">1</a><span class="space">&hellip;</span><a class="page-number" href="/null-index/page/16/">16</a><span class="page-number current">17</span><a class="page-number" href="/null-index/page/18/">18</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/null-index/page/18/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Feixiang Shu</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">60k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">1:49</span>
  </span>
</div>

<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("05/21/2025 10:00:00"); 
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒.";
    }
setInterval("createtime()",250);
</script>
    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
